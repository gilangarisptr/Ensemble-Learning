{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_learning",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxqAj5BsfQT+BT7ZhzJIFy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilangarisptr/Ensemble-learning/blob/main/Ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYVJfI-9PoMG"
      },
      "source": [
        "# Ensemble Learning\r\n",
        "\r\n",
        "**Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model**. To better understand this definition lets take a step back into ultimate goal of machine learning and model building. This is going to make more sense as I dive into specific examples and why Ensemble methods are used. in which we will be dealing with different ensemble learning techniques such as the following:\r\n",
        "* Averaging\r\n",
        "* Weighted Averaging\r\n",
        "* Max Voting\r\n",
        "* Bagging\r\n",
        "* Boosting\r\n",
        "* Blending\r\n",
        "\r\n",
        "![ensemble_learning.png](data:image/png;base64,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)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjW2TTYkPmbV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_M7LXSEWtf2"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zngbb1tAWw7m"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "data = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\r\n",
        "df = pd.read_csv(data,sep=',',header=None, na_values='?')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DWIT44zjX4Kt",
        "outputId": "1d2bc1fc-893b-4265-92f6-11d3215b9fae"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>202.0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>43.0</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>280.0</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY0cX3Xx43X_"
      },
      "source": [
        "## Preporcessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XemVZ1rlX5d2"
      },
      "source": [
        "df.loc[df[15]==\"+\", 15] = 1\r\n",
        "df.loc[df[15]==\"-\", 15] = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YVHIX9meYoem",
        "outputId": "e68e4870-6035-43c2-f84f-816e8f1ea2f4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>202.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>43.0</td>\n",
              "      <td>560</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>280.0</td>\n",
              "      <td>824</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  1\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  1\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  1\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  1\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRAt8SzpZYOF",
        "outputId": "8d7201bb-382c-4705-ae02-35b4d091ca42"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     12\n",
              "1     12\n",
              "2      0\n",
              "3      6\n",
              "4      6\n",
              "5      9\n",
              "6      9\n",
              "7      0\n",
              "8      0\n",
              "9      0\n",
              "10     0\n",
              "11     0\n",
              "12     0\n",
              "13    13\n",
              "14     0\n",
              "15     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vImgkuRLZd3N"
      },
      "source": [
        "df_clean = df.dropna(axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFF6YOUFZmSl",
        "outputId": "ae555ec5-2a19-483b-8f66-a73c250a8bab"
      },
      "source": [
        "df_clean.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9d9B_vCZqg9",
        "outputId": "8fec4c58-5d40-4f02-fe53-64aeaac11be7"
      },
      "source": [
        "df_clean.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgzZ_zsNZ5Xn",
        "outputId": "9882532b-bf6b-4fac-a31f-9e7c766dbd8f"
      },
      "source": [
        "df_clean.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 653 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       653 non-null    object \n",
            " 1   1       653 non-null    float64\n",
            " 2   2       653 non-null    float64\n",
            " 3   3       653 non-null    object \n",
            " 4   4       653 non-null    object \n",
            " 5   5       653 non-null    object \n",
            " 6   6       653 non-null    object \n",
            " 7   7       653 non-null    float64\n",
            " 8   8       653 non-null    object \n",
            " 9   9       653 non-null    object \n",
            " 10  10      653 non-null    int64  \n",
            " 11  11      653 non-null    object \n",
            " 12  12      653 non-null    object \n",
            " 13  13      653 non-null    float64\n",
            " 14  14      653 non-null    int64  \n",
            " 15  15      653 non-null    object \n",
            "dtypes: float64(4), int64(2), object(10)\n",
            "memory usage: 86.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vvGKTCuZ_Ge"
      },
      "source": [
        "df_cat = pd.get_dummies(df_clean[[0,3,4,5,6,8,9,11,12]])\r\n",
        "\r\n",
        "df_num = df_clean[[1,2,7,10,13,14]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcSkx77Wa1do"
      },
      "source": [
        "X = pd.concat([df_cat, df_num], axis=1)\r\n",
        "\r\n",
        "y = df_clean[15]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japoipW1bO4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b771b497-3a98-409a-a7b5-3bdfd1a81e1d"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_craMUJL4lc-",
        "outputId": "aba24516-b16f-46fe-d6d1-826dd43683ca"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "cmaslRnK6OuG",
        "outputId": "84f5c271-95bd-4072-838e-84f7d4f929cf"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "\r\n",
        "X_data = pd.DataFrame(scaler.fit_transform(X))\r\n",
        "X_data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.671648</td>\n",
              "      <td>0.671648</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>-0.294147</td>\n",
              "      <td>-0.505736</td>\n",
              "      <td>-0.255446</td>\n",
              "      <td>-0.203635</td>\n",
              "      <td>-0.195335</td>\n",
              "      <td>-0.287956</td>\n",
              "      <td>-0.303271</td>\n",
              "      <td>-0.124708</td>\n",
              "      <td>-0.281672</td>\n",
              "      <td>-0.248573</td>\n",
              "      <td>-0.360219</td>\n",
              "      <td>-0.067937</td>\n",
              "      <td>3.060242</td>\n",
              "      <td>-0.241551</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-0.30025</td>\n",
              "      <td>-0.515271</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.078507</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.844932</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.933306</td>\n",
              "      <td>0.933306</td>\n",
              "      <td>-1.129275</td>\n",
              "      <td>1.129275</td>\n",
              "      <td>0.927577</td>\n",
              "      <td>-0.927577</td>\n",
              "      <td>0.303271</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.056962</td>\n",
              "      <td>-0.961440</td>\n",
              "      <td>-0.295171</td>\n",
              "      <td>-0.302596</td>\n",
              "      <td>0.128682</td>\n",
              "      <td>-0.193125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.488875</td>\n",
              "      <td>-1.488875</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>-0.294147</td>\n",
              "      <td>-0.505736</td>\n",
              "      <td>-0.255446</td>\n",
              "      <td>-0.203635</td>\n",
              "      <td>-0.195335</td>\n",
              "      <td>-0.287956</td>\n",
              "      <td>-0.303271</td>\n",
              "      <td>-0.124708</td>\n",
              "      <td>-0.281672</td>\n",
              "      <td>-0.248573</td>\n",
              "      <td>2.776088</td>\n",
              "      <td>-0.067937</td>\n",
              "      <td>-0.326772</td>\n",
              "      <td>-0.241551</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-0.30025</td>\n",
              "      <td>1.940728</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.078507</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-1.183527</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.933306</td>\n",
              "      <td>0.933306</td>\n",
              "      <td>-1.129275</td>\n",
              "      <td>1.129275</td>\n",
              "      <td>0.927577</td>\n",
              "      <td>-0.927577</td>\n",
              "      <td>0.303271</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>2.296536</td>\n",
              "      <td>-0.073565</td>\n",
              "      <td>0.236217</td>\n",
              "      <td>0.704516</td>\n",
              "      <td>-0.816802</td>\n",
              "      <td>-0.086443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.488875</td>\n",
              "      <td>-1.488875</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>-0.294147</td>\n",
              "      <td>-0.505736</td>\n",
              "      <td>-0.255446</td>\n",
              "      <td>-0.203635</td>\n",
              "      <td>-0.195335</td>\n",
              "      <td>-0.287956</td>\n",
              "      <td>-0.303271</td>\n",
              "      <td>-0.124708</td>\n",
              "      <td>-0.281672</td>\n",
              "      <td>-0.248573</td>\n",
              "      <td>2.776088</td>\n",
              "      <td>-0.067937</td>\n",
              "      <td>-0.326772</td>\n",
              "      <td>-0.241551</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-0.30025</td>\n",
              "      <td>1.940728</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.078507</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-1.183527</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.933306</td>\n",
              "      <td>0.933306</td>\n",
              "      <td>0.885524</td>\n",
              "      <td>-0.885524</td>\n",
              "      <td>0.927577</td>\n",
              "      <td>-0.927577</td>\n",
              "      <td>0.303271</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.592078</td>\n",
              "      <td>-0.861903</td>\n",
              "      <td>-0.220955</td>\n",
              "      <td>-0.504019</td>\n",
              "      <td>0.592504</td>\n",
              "      <td>-0.036150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.671648</td>\n",
              "      <td>0.671648</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>-0.294147</td>\n",
              "      <td>-0.505736</td>\n",
              "      <td>-0.255446</td>\n",
              "      <td>-0.203635</td>\n",
              "      <td>-0.195335</td>\n",
              "      <td>-0.287956</td>\n",
              "      <td>-0.303271</td>\n",
              "      <td>-0.124708</td>\n",
              "      <td>-0.281672</td>\n",
              "      <td>-0.248573</td>\n",
              "      <td>-0.360219</td>\n",
              "      <td>-0.067937</td>\n",
              "      <td>3.060242</td>\n",
              "      <td>-0.241551</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-0.30025</td>\n",
              "      <td>-0.515271</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.078507</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.844932</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.933306</td>\n",
              "      <td>0.933306</td>\n",
              "      <td>-1.129275</td>\n",
              "      <td>1.129275</td>\n",
              "      <td>-1.078078</td>\n",
              "      <td>1.078078</td>\n",
              "      <td>0.303271</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.310572</td>\n",
              "      <td>-0.654865</td>\n",
              "      <td>0.446990</td>\n",
              "      <td>0.503093</td>\n",
              "      <td>-0.477855</td>\n",
              "      <td>-0.192553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.671648</td>\n",
              "      <td>0.671648</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>0.555533</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>-0.550811</td>\n",
              "      <td>-0.294147</td>\n",
              "      <td>-0.505736</td>\n",
              "      <td>-0.255446</td>\n",
              "      <td>-0.203635</td>\n",
              "      <td>-0.195335</td>\n",
              "      <td>-0.287956</td>\n",
              "      <td>-0.303271</td>\n",
              "      <td>-0.124708</td>\n",
              "      <td>-0.281672</td>\n",
              "      <td>-0.248573</td>\n",
              "      <td>-0.360219</td>\n",
              "      <td>-0.067937</td>\n",
              "      <td>3.060242</td>\n",
              "      <td>-0.241551</td>\n",
              "      <td>-0.297209</td>\n",
              "      <td>-0.096299</td>\n",
              "      <td>-0.30025</td>\n",
              "      <td>-0.515271</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.078507</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>0.844932</td>\n",
              "      <td>-0.111369</td>\n",
              "      <td>-0.933306</td>\n",
              "      <td>0.933306</td>\n",
              "      <td>0.885524</td>\n",
              "      <td>-0.885524</td>\n",
              "      <td>0.927577</td>\n",
              "      <td>-0.927577</td>\n",
              "      <td>-3.297382</td>\n",
              "      <td>-0.055427</td>\n",
              "      <td>3.364633</td>\n",
              "      <td>-0.958122</td>\n",
              "      <td>0.158358</td>\n",
              "      <td>-0.158613</td>\n",
              "      <td>-0.504019</td>\n",
              "      <td>-0.358926</td>\n",
              "      <td>-0.193125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        43        44        45\n",
              "0 -0.671648  0.671648 -0.055427  ... -0.302596  0.128682 -0.193125\n",
              "1  1.488875 -1.488875 -0.055427  ...  0.704516 -0.816802 -0.086443\n",
              "2  1.488875 -1.488875 -0.055427  ... -0.504019  0.592504 -0.036150\n",
              "3 -0.671648  0.671648 -0.055427  ...  0.503093 -0.477855 -0.192553\n",
              "4 -0.671648  0.671648 -0.055427  ... -0.504019 -0.358926 -0.193125\n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcRfFDX484Ne"
      },
      "source": [
        "y = y.astype('int')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr_PYYym5kmm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_data,y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUrVr62c8RCc",
        "outputId": "b48f0a37-b3e8-4e44-cad7-aa3591281be7"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "513    1\n",
              "142    1\n",
              "325    0\n",
              "555    1\n",
              "567    1\n",
              "Name: 15, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdhOQDm_8NyW",
        "outputId": "0871c8d2-4a71-47a8-9e1f-e5c68277a8f9"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(457, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on0Cyc3g5CyF"
      },
      "source": [
        "## Modeling Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRRSTnWU5EPk",
        "outputId": "52979aaa-fb41-445c-f70f-6ff22434e023"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "# define logistic regression\r\n",
        "\r\n",
        "Modellr = LogisticRegression()\r\n",
        "Modellr.fit(x_train, y_train)\r\n",
        "#fitting model\r\n",
        "\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nULPogCB7vDa"
      },
      "source": [
        "pred = Modellr.predict(x_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72iK--4o9d8k",
        "outputId": "869142e8-a70d-4fc8-d8bd-0e9a68fd6bc6"
      },
      "source": [
        "pred"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsTXidH39e_E",
        "outputId": "cb2567df-7df7-46be-a181-052855f1f1ef"
      },
      "source": [
        "Modellr.score(x_test,y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8520408163265306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "filr-t0B9v3c",
        "outputId": "7df3b009-0f6d-4c49-ded9-29137a611056"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "# Confusion Matrix for the model\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "# Classification report for the model\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[91 19]\n",
            " [10 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.83      0.86       110\n",
            "           1       0.80      0.88      0.84        86\n",
            "\n",
            "    accuracy                           0.85       196\n",
            "   macro avg       0.85      0.86      0.85       196\n",
            "weighted avg       0.86      0.85      0.85       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96D7rd7n_Fnk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YI0q4KiGrqq"
      },
      "source": [
        "## Ensemble Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPuDfNOs_VB4"
      },
      "source": [
        "### Averaging\r\n",
        "\r\n",
        "Averaging is a naïve way of doing ensemble learning; however, it is extremely useful too. The basic idea behind this technique is to take the predictions of multiple individual models and then average the predictions to generate a final prediction. The assumption is that by averaging the predictions of different individual learners, we eliminate the errors made by individual learners, thereby generating a model superior to the base model. One prerequisite to make averaging work is to have the predictions of the base models be uncorrelated. This would mean that the individual models should not make the same kinds of errors. The diversity of the models is a critical aspect to ensure uncorrelated errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEe1IqJv_kX8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "model1 = LogisticRegression(random_state=123)\r\n",
        "model2 = KNeighborsClassifier(n_neighbors=5)\r\n",
        "model3 = RandomForestClassifier(n_estimators=500)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PfuOyF0AT8V",
        "outputId": "f420cc38-f6be-42b2-ca29-27353c5eac19"
      },
      "source": [
        "# Fitting all three models on the training data\r\n",
        "model1.fit(x_train,y_train)\r\n",
        "model2.fit(x_train,y_train)\r\n",
        "model3.fit(x_train,y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4qIluMDAadl"
      },
      "source": [
        "\"\"\"\r\n",
        "Predicting probabilities of each model \r\n",
        "on the test set\r\n",
        "\"\"\"\r\n",
        "pred1=model1.predict_proba(x_test)\r\n",
        "pred2=model2.predict_proba(x_test)\r\n",
        "pred3=model3.predict_proba(x_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKyIpjWWAilM"
      },
      "source": [
        "avg_ensemble = (pred1 + pred2 + pred3)/3"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ef1rfNpApS8",
        "outputId": "48095df1-7c87-4305-e186-1a16de82d116"
      },
      "source": [
        "# Printing the order of classes for each model\r\n",
        "print(model1.classes_)\r\n",
        "print(model2.classes_)\r\n",
        "print(model3.classes_)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6WI735oBAmk",
        "outputId": "b4daa4c4-2779-4e7d-a703-e4f08c19b2ac"
      },
      "source": [
        "import numpy as np\r\n",
        "pred = np.argmax(avg_ensemble,axis = 1)\r\n",
        "pred"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vv0NRaQBMX1",
        "outputId": "cf86c1f8-d039-48ff-db08-5561a5a197c1"
      },
      "source": [
        "#generating confusion matrix\r\n",
        "\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[92 18]\n",
            " [ 9 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.84      0.87       110\n",
            "           1       0.81      0.90      0.85        86\n",
            "\n",
            "    accuracy                           0.86       196\n",
            "   macro avg       0.86      0.87      0.86       196\n",
            "weighted avg       0.87      0.86      0.86       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVFtY5CxF6kL"
      },
      "source": [
        "after used averaging ensembling our recall and f-1 score incresead. WOW! it's amazing right? but our f1-score and recall is still under 90%, especially for 0 recall we just got 84%. hmm... we must incresead that number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS7ya0JHGiO7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQllBYhG4Xq"
      },
      "source": [
        "### Weighted Averaging\r\n",
        "\r\n",
        "Weighted averaging is an extension of the averaging method that we saw earlier. The major difference in both of these approaches is in the way the combined predictions are generated. In the weighted averaging method, we assign weights to each model's predictions and then generate the combined predictions. The weights are assigned based on our judgment of which model would be the most influential in the ensemble. These weights, which are initially assigned arbitrarily, have to be evolved after a lot of experimentation. To start off, we assume some weights and then iterate with different weights for each model to verify whether we get any improvements in the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C6suU3pHCpe",
        "outputId": "fef29840-b1bf-41b3-f41b-3483094ab247"
      },
      "source": [
        "\"\"\"\r\n",
        "Calculating the ensemble prediction by applying \r\n",
        "weights for each prediction\r\n",
        "\"\"\"\r\n",
        "ensemblepred=(pred1 *0.60 + pred2 * 0.20 + pred3 * 0.20)\r\n",
        "\r\n",
        "pred = np.argmax(ensemblepred, axis=1)\r\n",
        "\r\n",
        "#print(score(y_test, pred))\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[93 17]\n",
            " [ 7 79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.85      0.89       110\n",
            "           1       0.82      0.92      0.87        86\n",
            "\n",
            "    accuracy                           0.88       196\n",
            "   macro avg       0.88      0.88      0.88       196\n",
            "weighted avg       0.88      0.88      0.88       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1FCGkDAIIXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUF2nD9tOM2L"
      },
      "source": [
        "### Max Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2_Bf2n0Oh7H"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQb_vQ-OQgn",
        "outputId": "47b01247-751c-455c-af20-66167dd1bbb1"
      },
      "source": [
        "# Defining the ensemble model using VotingClassifier\r\n",
        "model = VotingClassifier(estimators=[('lr', model1),\\\r\n",
        "                        ('knn', model2),('rf', model3)],\\\r\n",
        "                         voting= 'hard')\r\n",
        "\r\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr',\n",
              "                              LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=123,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False)),\n",
              "                             ('knn',\n",
              "                              KNeighborsClassifier(algorithm='auto',\n",
              "                                                   leaf_size=30,\n",
              "                                                   metric='minkowski',\n",
              "                                                   me...\n",
              "                                                     criterion='gini',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     n_estimators=500,\n",
              "                                                     n_jobs=None,\n",
              "                                                     oob_score=False,\n",
              "                                                     random_state=None,\n",
              "                                                     verbose=0,\n",
              "                                                     warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV5A3KM_OdCQ",
        "outputId": "cfab6234-fcda-49a2-8607-339190ffc1f1"
      },
      "source": [
        "model.score(x_test,y_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8673469387755102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa1Ow9AMOsBf",
        "outputId": "a0e6c829-c912-4f08-e701-acdd89c4c527"
      },
      "source": [
        "pred = model.predict(x_test)\r\n",
        "\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[93 17]\n",
            " [ 9 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88       110\n",
            "           1       0.82      0.90      0.86        86\n",
            "\n",
            "    accuracy                           0.87       196\n",
            "   macro avg       0.87      0.87      0.87       196\n",
            "weighted avg       0.87      0.87      0.87       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSafKfDCPFkX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF_dTVCtTCbD"
      },
      "source": [
        "### Bagging (Boosting Aggregating)\r\n",
        "\r\n",
        "Bagging is a pseudonym for Bootstrap Aggregating. Before we explain how bagging works, let's describe what bootstrapping is. Bootstrapping has its etymological origins in the phrase, Pulling oneself up by one's bootstrap. The essence of this phrase is to make the best use of the available resources. In the statistical context, bootstrapping entails taking samples from the available dataset by replacement. Let's look at this concept with a toy example.\r\n",
        "\r\n",
        "Suppose we have a dataset consisting of 10 numbers from 1 to 10. We now need to create 4 different datasets of 10 each from the available dataset. How do we do this? This is where the concept of bootstrapping comes in handy. In this method, we take samples from the available dataset one by one and then replace the number we took before taking the next sample. We continue with this until we get a sample with the number of data points we need. As we are replacing each number after it is selected, there is a chance that we might have more than one of a given data point in a sample\r\n",
        "\r\n",
        "When implementing bagging, we use a function called BaggingClassifier(), which is available in the Scikit learn library. Some of the important arguments that are provided when creating an ensemble model include the following:\r\n",
        "\r\n",
        "* base_estimator: This argument is to define the base estimator to be used.\r\n",
        "* n_estimator: This argument defines the number of base estimators that will be used in the ensemble.\r\n",
        "* max_samples: The maximum size of the bootstrapped sample for fitting the base estimator is defined using this argument. This is represented as a proportion (0.8, 0.7, and so on).\r\n",
        "* max_features: When fitting multiple individual learners, it has been found that randomly selecting the features to be used in each dataset results in superior performance. The max_features argument indicates the number of features to be used. For example, if there were 10 features in the dataset and the max_features argument was to be defined as 0.8, then only 8 (0.8 x 10) features would be used to fit a model using the base learner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8rJMQMsTM-Q"
      },
      "source": [
        "# Defining the base learner\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "bl1 = RandomForestClassifier(random_state=123)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN8FPxoqThES"
      },
      "source": [
        "# Creating the bagging meta learner\r\n",
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "\r\n",
        "baggingLearner = BaggingClassifier(base_estimator=bl1, n_estimators=10, max_samples=0.9, max_features=0.9)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_SB9IBjTpEQ"
      },
      "source": [
        "model = baggingLearner.fit(x_train, y_train)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l2dWXVMTweI"
      },
      "source": [
        "# Predicting on the test set using the model\r\n",
        "pred = model.predict(x_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlpnSXFIT1Yi",
        "outputId": "d631a90c-1e41-443d-8cce-9d2f456edbe1"
      },
      "source": [
        "print(confusion_matrix(y_test, pred))\r\n",
        "\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[94 16]\n",
            " [12 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87       110\n",
            "           1       0.82      0.86      0.84        86\n",
            "\n",
            "    accuracy                           0.86       196\n",
            "   macro avg       0.85      0.86      0.86       196\n",
            "weighted avg       0.86      0.86      0.86       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O08fnxAT-2A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFg5ox8aUsDl"
      },
      "source": [
        "### Boosting\r\n",
        "\r\n",
        "The bagging technique, which we discussed in the last section, can be termed as a parallel learning technique. This means that each base learner is fit independently of the other and their predictions are aggregated. Unlike the bagging method, boosting works in a sequential manner. It works on the principle of correcting the prediction errors of each base learner. The base learners are fit sequentially one after the other. A base learner tries to correct the error generated by the previous learner and this process continues until a superior meta learner is created. The steps involved in the boosting technique are as follows:\r\n",
        "\r\n",
        "1. A base learner is fit on a subset of the dataset.\r\n",
        "2. Once the model is fit, predictions are made on the entire dataset.\r\n",
        "3. The errors in the predictions are identified by comparing them with the actual labels.\r\n",
        "4. Those examples that generated the wrong predictions are given larger weights.\r\n",
        "5. Another base learner is fit on the dataset where the weights of the wrongly predicted examples in the previous step are altered.\r\n",
        "6. This base learner tries to correct the errors of the earlier model and gives their predictions.\r\n",
        "Steps 4, 5, and 6 are repeated until a strong meta learner is generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gljEsB3DU8so",
        "outputId": "a51f7d6e-fcb2-45df-b53a-da1a5c46317a"
      },
      "source": [
        "# Defining the base learner\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "bl1 = RandomForestClassifier(random_state=123)\r\n",
        "# Defining the boosting meta learner\r\n",
        "from sklearn.ensemble import AdaBoostClassifier\r\n",
        "boosting = AdaBoostClassifier(base_estimator=bl1, \\\r\n",
        "                              n_estimators=300)\r\n",
        "# Fitting the model on the training set\r\n",
        "model = boosting.fit(x_train, y_train)\r\n",
        "# Getting the predictions from the boosting model\r\n",
        "pred = model.predict(x_test)\r\n",
        "# Printing the confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "# Printing the classification report\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[96 14]\n",
            " [13 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       110\n",
            "           1       0.84      0.85      0.84        86\n",
            "\n",
            "    accuracy                           0.86       196\n",
            "   macro avg       0.86      0.86      0.86       196\n",
            "weighted avg       0.86      0.86      0.86       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsPgXS7VWbp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsMcHDDiVkd1"
      },
      "source": [
        "### Stacking\r\n",
        "\r\n",
        "Stacking: Define the base learners and meta learner, create the stacking classifier, fit the model, generate the predictions, and print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7cKt7XqVsBp",
        "outputId": "6e3a00c4-60ce-45f2-cf1b-8c6b3c9c6fdf"
      },
      "source": [
        "# Importing the meta learner and base learners\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "bl1 = KNeighborsClassifier(n_neighbors=5)\r\n",
        "bl2 = LogisticRegression(random_state=123) \r\n",
        "ml = RandomForestClassifier(random_state=123)\r\n",
        "# Creating the stacking classifier\r\n",
        "from mlxtend.classifier import StackingClassifier\r\n",
        "stackclf = StackingClassifier(classifiers=[bl1, bl2], \\\r\n",
        "                              meta_classifier=ml)\r\n",
        "# Fitting the model on the training set\r\n",
        "model = stackclf.fit(x_train, y_train)\r\n",
        "# Generating predictions on test set\r\n",
        "pred = model.predict(x_test)\r\n",
        "# Printing the confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(confusion_matrix(y_test, pred))\r\n",
        "# Printing the classification report\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[91 19]\n",
            " [10 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.83      0.86       110\n",
            "           1       0.80      0.88      0.84        86\n",
            "\n",
            "    accuracy                           0.85       196\n",
            "   macro avg       0.85      0.86      0.85       196\n",
            "weighted avg       0.86      0.85      0.85       196\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb8EKo3sVu95"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}